{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memory_networks",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v4jMLaWcbe6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVlogkVqcZuS"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwEHJflvcZT-"
      },
      "source": [
        "## Single Supporting Fact story"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZQaL4vqWpPs"
      },
      "source": [
        "with open(\"drive/MyDrive/data_science/memory_networks/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)\n",
        "\n",
        "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFHZSk-OWpSa"
      },
      "source": [
        "all_data = test_data + train_data\n",
        "\n",
        "\n",
        "# Create a set that holds the vocab words\n",
        "vocab = set()\n",
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "\n",
        "# Add no and yes as they are the vocabulary of answers\n",
        "vocab.add('no')\n",
        "vocab.add('yes')\n",
        "\n",
        "# Extra space to hold a 0 for Keras's pad_sequences\n",
        "vocab_len = len(vocab) + 1\n",
        "\n",
        "# Max story length and max question length\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "max_question_len = max([len(data[1]) for data in all_data])\n",
        "\n",
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYltcOreWpWD"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)\n",
        "\n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Jppn5cWpYr"
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    # Vectorize stories by storing them as sequences\n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp0g0CcZWpbL"
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
        "\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBD1MdF_Wpdz"
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv9AG9PcXzkX"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgjJ7Iv4WpgN",
        "outputId": "34529331-f8dd-4b04-ca01-6c484352658c"
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)\n",
        "\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)\n",
        "\n",
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
        "\n",
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "\n",
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "\n",
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential_3[0][0]               \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           1254        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7fqfbLIYHB9",
        "outputId": "45eef27b-7431-44d1-e8dc-c1aefd4fd9d6"
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 8s 17ms/step - loss: 0.8885 - accuracy: 0.4967 - val_loss: 0.6978 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.7033 - accuracy: 0.5017 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6959 - accuracy: 0.5005 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.5067 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6951 - accuracy: 0.4952 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6949 - accuracy: 0.4935 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6946 - accuracy: 0.4973 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6939 - accuracy: 0.5030 - val_loss: 0.6964 - val_accuracy: 0.4970\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.5020 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6944 - accuracy: 0.4900 - val_loss: 0.6946 - val_accuracy: 0.5050\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6910 - accuracy: 0.5176 - val_loss: 0.6886 - val_accuracy: 0.5290\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6731 - accuracy: 0.5765 - val_loss: 0.6583 - val_accuracy: 0.6470\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6487 - accuracy: 0.6369 - val_loss: 0.6293 - val_accuracy: 0.6570\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6300 - accuracy: 0.6533 - val_loss: 0.6183 - val_accuracy: 0.6710\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6211 - accuracy: 0.6642 - val_loss: 0.6147 - val_accuracy: 0.6630\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6181 - accuracy: 0.6639 - val_loss: 0.6120 - val_accuracy: 0.6670\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6143 - accuracy: 0.6668 - val_loss: 0.6228 - val_accuracy: 0.6600\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6109 - accuracy: 0.6729 - val_loss: 0.6081 - val_accuracy: 0.6740\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6052 - accuracy: 0.6766 - val_loss: 0.6026 - val_accuracy: 0.6730\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6068 - accuracy: 0.6764 - val_loss: 0.5971 - val_accuracy: 0.6720\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5967 - accuracy: 0.6810 - val_loss: 0.5989 - val_accuracy: 0.6780\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5825 - accuracy: 0.6996 - val_loss: 0.5787 - val_accuracy: 0.6870\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5748 - accuracy: 0.7020 - val_loss: 0.5725 - val_accuracy: 0.6950\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5637 - accuracy: 0.7096 - val_loss: 0.5586 - val_accuracy: 0.7040\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5496 - accuracy: 0.7140 - val_loss: 0.5599 - val_accuracy: 0.7140\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5416 - accuracy: 0.7280 - val_loss: 0.5469 - val_accuracy: 0.7140\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5302 - accuracy: 0.7331 - val_loss: 0.5479 - val_accuracy: 0.7170\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5233 - accuracy: 0.7408 - val_loss: 0.5313 - val_accuracy: 0.7270\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5154 - accuracy: 0.7471 - val_loss: 0.5659 - val_accuracy: 0.7050\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4990 - accuracy: 0.7584 - val_loss: 0.5138 - val_accuracy: 0.7370\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4964 - accuracy: 0.7578 - val_loss: 0.5125 - val_accuracy: 0.7230\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4847 - accuracy: 0.7646 - val_loss: 0.5033 - val_accuracy: 0.7480\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4852 - accuracy: 0.7601 - val_loss: 0.4915 - val_accuracy: 0.7490\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4779 - accuracy: 0.7705 - val_loss: 0.5327 - val_accuracy: 0.7490\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4736 - accuracy: 0.7669 - val_loss: 0.4950 - val_accuracy: 0.7480\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4679 - accuracy: 0.7693 - val_loss: 0.4772 - val_accuracy: 0.7610\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4630 - accuracy: 0.7704 - val_loss: 0.4922 - val_accuracy: 0.7460\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4601 - accuracy: 0.7746 - val_loss: 0.4743 - val_accuracy: 0.7620\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4571 - accuracy: 0.7700 - val_loss: 0.4691 - val_accuracy: 0.7660\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4529 - accuracy: 0.7787 - val_loss: 0.4749 - val_accuracy: 0.7640\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4463 - accuracy: 0.7834 - val_loss: 0.4536 - val_accuracy: 0.7750\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4421 - accuracy: 0.7873 - val_loss: 0.4711 - val_accuracy: 0.7820\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4318 - accuracy: 0.7914 - val_loss: 0.4567 - val_accuracy: 0.7770\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.4335 - accuracy: 0.7939 - val_loss: 0.4504 - val_accuracy: 0.7690\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4274 - accuracy: 0.7938 - val_loss: 0.4456 - val_accuracy: 0.7810\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4230 - accuracy: 0.7959 - val_loss: 0.4517 - val_accuracy: 0.7700\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4198 - accuracy: 0.8007 - val_loss: 0.4604 - val_accuracy: 0.7720\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4116 - accuracy: 0.8020 - val_loss: 0.4488 - val_accuracy: 0.7780\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4063 - accuracy: 0.8036 - val_loss: 0.4357 - val_accuracy: 0.7860\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4059 - accuracy: 0.8051 - val_loss: 0.4475 - val_accuracy: 0.7860\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4000 - accuracy: 0.8120 - val_loss: 0.4311 - val_accuracy: 0.7920\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3906 - accuracy: 0.8113 - val_loss: 0.4705 - val_accuracy: 0.7760\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3893 - accuracy: 0.8194 - val_loss: 0.4437 - val_accuracy: 0.7920\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3803 - accuracy: 0.8225 - val_loss: 0.5436 - val_accuracy: 0.7560\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3778 - accuracy: 0.8223 - val_loss: 0.4538 - val_accuracy: 0.7960\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3781 - accuracy: 0.8221 - val_loss: 0.4392 - val_accuracy: 0.7850\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3703 - accuracy: 0.8330 - val_loss: 0.4454 - val_accuracy: 0.8030\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3691 - accuracy: 0.8309 - val_loss: 0.4329 - val_accuracy: 0.7870\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3662 - accuracy: 0.8288 - val_loss: 0.4326 - val_accuracy: 0.7960\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3559 - accuracy: 0.8424 - val_loss: 0.4460 - val_accuracy: 0.7950\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3475 - accuracy: 0.8444 - val_loss: 0.4845 - val_accuracy: 0.7920\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3500 - accuracy: 0.8438 - val_loss: 0.4296 - val_accuracy: 0.7930\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3430 - accuracy: 0.8455 - val_loss: 0.4425 - val_accuracy: 0.7930\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3405 - accuracy: 0.8496 - val_loss: 0.4569 - val_accuracy: 0.7910\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3402 - accuracy: 0.8494 - val_loss: 0.4278 - val_accuracy: 0.7940\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3331 - accuracy: 0.8516 - val_loss: 0.4459 - val_accuracy: 0.7910\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3357 - accuracy: 0.8527 - val_loss: 0.4584 - val_accuracy: 0.7990\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3338 - accuracy: 0.8524 - val_loss: 0.5075 - val_accuracy: 0.7840\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3311 - accuracy: 0.8547 - val_loss: 0.4450 - val_accuracy: 0.7960\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3299 - accuracy: 0.8547 - val_loss: 0.4661 - val_accuracy: 0.8020\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3224 - accuracy: 0.8565 - val_loss: 0.4692 - val_accuracy: 0.7960\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3216 - accuracy: 0.8605 - val_loss: 0.4806 - val_accuracy: 0.7940\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3162 - accuracy: 0.8650 - val_loss: 0.4716 - val_accuracy: 0.7990\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3176 - accuracy: 0.8611 - val_loss: 0.4947 - val_accuracy: 0.7910\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3168 - accuracy: 0.8624 - val_loss: 0.4617 - val_accuracy: 0.7890\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3126 - accuracy: 0.8647 - val_loss: 0.4629 - val_accuracy: 0.7980\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3114 - accuracy: 0.8646 - val_loss: 0.5401 - val_accuracy: 0.7920\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3051 - accuracy: 0.8675 - val_loss: 0.4714 - val_accuracy: 0.7860\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3063 - accuracy: 0.8672 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3057 - accuracy: 0.8709 - val_loss: 0.4868 - val_accuracy: 0.7960\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3020 - accuracy: 0.8708 - val_loss: 0.5258 - val_accuracy: 0.7940\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2990 - accuracy: 0.8679 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2964 - accuracy: 0.8716 - val_loss: 0.5303 - val_accuracy: 0.7940\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2964 - accuracy: 0.8722 - val_loss: 0.4979 - val_accuracy: 0.7860\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2902 - accuracy: 0.8729 - val_loss: 0.4880 - val_accuracy: 0.7950\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2907 - accuracy: 0.8794 - val_loss: 0.4888 - val_accuracy: 0.7870\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2888 - accuracy: 0.8772 - val_loss: 0.5295 - val_accuracy: 0.7880\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2846 - accuracy: 0.8758 - val_loss: 0.5104 - val_accuracy: 0.7810\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2829 - accuracy: 0.8786 - val_loss: 0.5097 - val_accuracy: 0.7950\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2865 - accuracy: 0.8782 - val_loss: 0.5440 - val_accuracy: 0.7870\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2787 - accuracy: 0.8813 - val_loss: 0.5224 - val_accuracy: 0.7850\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2775 - accuracy: 0.8815 - val_loss: 0.5463 - val_accuracy: 0.7980\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2760 - accuracy: 0.8815 - val_loss: 0.5765 - val_accuracy: 0.7790\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2673 - accuracy: 0.8878 - val_loss: 0.5447 - val_accuracy: 0.7850\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2658 - accuracy: 0.8865 - val_loss: 0.5466 - val_accuracy: 0.7840\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2730 - accuracy: 0.8851 - val_loss: 0.5360 - val_accuracy: 0.7850\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2661 - accuracy: 0.8887 - val_loss: 0.5623 - val_accuracy: 0.7940\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2611 - accuracy: 0.8900 - val_loss: 0.5580 - val_accuracy: 0.7950\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2595 - accuracy: 0.8883 - val_loss: 0.5719 - val_accuracy: 0.7900\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2647 - accuracy: 0.8890 - val_loss: 0.5384 - val_accuracy: 0.7920\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2647 - accuracy: 0.8905 - val_loss: 0.5312 - val_accuracy: 0.7900\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2639 - accuracy: 0.8897 - val_loss: 0.5654 - val_accuracy: 0.7860\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2594 - accuracy: 0.8902 - val_loss: 0.5598 - val_accuracy: 0.7940\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2529 - accuracy: 0.8924 - val_loss: 0.5290 - val_accuracy: 0.7950\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2532 - accuracy: 0.8955 - val_loss: 0.5494 - val_accuracy: 0.7900\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2504 - accuracy: 0.8964 - val_loss: 0.5493 - val_accuracy: 0.7960\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2447 - accuracy: 0.9004 - val_loss: 0.5593 - val_accuracy: 0.7950\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2494 - accuracy: 0.8950 - val_loss: 0.7070 - val_accuracy: 0.7770\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2532 - accuracy: 0.8948 - val_loss: 0.5592 - val_accuracy: 0.7970\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2390 - accuracy: 0.8982 - val_loss: 0.5934 - val_accuracy: 0.7930\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2441 - accuracy: 0.8998 - val_loss: 0.5624 - val_accuracy: 0.7930\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2455 - accuracy: 0.9005 - val_loss: 0.6114 - val_accuracy: 0.7900\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2413 - accuracy: 0.9007 - val_loss: 0.6090 - val_accuracy: 0.7840\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2321 - accuracy: 0.9037 - val_loss: 0.5637 - val_accuracy: 0.7990\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2438 - accuracy: 0.8996 - val_loss: 0.5529 - val_accuracy: 0.7960\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2363 - accuracy: 0.9011 - val_loss: 0.5442 - val_accuracy: 0.8060\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2222 - accuracy: 0.9074 - val_loss: 0.6299 - val_accuracy: 0.8020\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2317 - accuracy: 0.9066 - val_loss: 0.5296 - val_accuracy: 0.7940\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2209 - accuracy: 0.9073 - val_loss: 0.5812 - val_accuracy: 0.7940\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2243 - accuracy: 0.9086 - val_loss: 0.5748 - val_accuracy: 0.7950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6OfdqyDQbBT",
        "outputId": "1e293c0e-e5f5-4715-ce5e-f6dcc8559ce4"
      },
      "source": [
        "filename = 'chatbot.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yiaAhRINQbDw",
        "outputId": "bd706141-beec-47b5-ef0d-51a6cd11c3ca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0VJtsVgbQku"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}