{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Activation, dot, Lambda, Reshape, Add\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\IMP\\\\datasets\\\\bAbI_datasets\\\\tasks_1-20_v1-2\\\\en-10k\"\n",
    "\n",
    "def load_data(given_dir):\n",
    "    with open(\"{}\\\\{}\".format(data_dir, given_dir), encoding=\"utf8\") as f:\n",
    "        story = []\n",
    "        question = []\n",
    "        answer = []\n",
    "        data = []\n",
    "        for line in f:\n",
    "                number, sentence = line.split(\" \", 1)\n",
    "\n",
    "                # New story\n",
    "                if int(number) == 1:\n",
    "                    story = []\n",
    "\n",
    "                tokenized_story = re.findall(r\"[A-Za-z]+|[,.?]\", sentence.strip())\n",
    "\n",
    "                # Answer and the supporting number is in the line both seperated by a tab.\n",
    "                if \"\\t\" in sentence:\n",
    "                    question, answer, supporting_number = sentence.split(\"\\t\")\n",
    "                    tokenized_question = re.findall(r\"[A-Za-z]+|[,.?]\", question.strip())\n",
    "                    tokenized_answer = re.findall(r\"[A-Za-z]+|[,.?]\", answer.strip())\n",
    "                    story_so_far = [[str(i)] + s for i, s in enumerate(story)]\n",
    "                    data.append((story_so_far, tokenized_question, tokenized_answer))\n",
    "                else:\n",
    "                    story.append(tokenized_story)\n",
    "        \n",
    "        return data\n",
    "\n",
    "df_train = load_data(\"qa2_two-supporting-facts_train.txt\")\n",
    "df_test = load_data(\"qa2_two-supporting-facts_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings(data):\n",
    "    # Get the mappings\n",
    "    word2idx = {\"<PAD>\": 0}\n",
    "\n",
    "    count = 1\n",
    "    for stories, question, answer in data:\n",
    "        for story in stories:\n",
    "            for word in story:\n",
    "                if word not in word2idx:\n",
    "                    word2idx[word] = count \n",
    "                    count += 1\n",
    "        for word in question:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = count \n",
    "                count += 1\n",
    "        for word in answer:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = count \n",
    "                count += 1\n",
    "\n",
    "    idx2word = {v: k for k, v in word2idx.items()}\n",
    "    \n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '0': 1,\n",
       " 'Mary': 2,\n",
       " 'moved': 3,\n",
       " 'to': 4,\n",
       " 'the': 5,\n",
       " 'bathroom': 6,\n",
       " '.': 7,\n",
       " '1': 8,\n",
       " 'Sandra': 9,\n",
       " 'journeyed': 10,\n",
       " 'bedroom': 11,\n",
       " '2': 12,\n",
       " 'got': 13,\n",
       " 'football': 14,\n",
       " 'there': 15,\n",
       " '3': 16,\n",
       " 'John': 17,\n",
       " 'went': 18,\n",
       " 'kitchen': 19,\n",
       " '4': 20,\n",
       " 'back': 21,\n",
       " '5': 22,\n",
       " 'garden': 23,\n",
       " 'Where': 24,\n",
       " 'is': 25,\n",
       " '?': 26,\n",
       " '6': 27,\n",
       " 'office': 28,\n",
       " '7': 29,\n",
       " '8': 30,\n",
       " 'hallway': 31,\n",
       " '9': 32,\n",
       " 'Daniel': 33,\n",
       " '10': 34,\n",
       " 'dropped': 35,\n",
       " '11': 36,\n",
       " 'milk': 37,\n",
       " '12': 38,\n",
       " 'took': 39,\n",
       " '13': 40,\n",
       " 'picked': 41,\n",
       " 'up': 42,\n",
       " 'apple': 43,\n",
       " '14': 44,\n",
       " 'travelled': 45,\n",
       " '15': 46,\n",
       " '16': 47,\n",
       " '17': 48,\n",
       " 'left': 49,\n",
       " '18': 50,\n",
       " '19': 51,\n",
       " '20': 52,\n",
       " '21': 53,\n",
       " '22': 54,\n",
       " '23': 55,\n",
       " '24': 56,\n",
       " '25': 57,\n",
       " 'grabbed': 58,\n",
       " 'discarded': 59,\n",
       " 'put': 60,\n",
       " 'down': 61,\n",
       " '26': 62,\n",
       " '27': 63,\n",
       " '28': 64,\n",
       " '29': 65,\n",
       " '30': 66,\n",
       " '31': 67,\n",
       " '32': 68,\n",
       " '33': 69,\n",
       " '34': 70,\n",
       " '35': 71,\n",
       " '36': 72,\n",
       " '37': 73,\n",
       " '38': 74,\n",
       " '39': 75,\n",
       " '40': 76,\n",
       " '41': 77,\n",
       " '42': 78,\n",
       " '43': 79,\n",
       " '44': 80,\n",
       " '45': 81,\n",
       " '46': 82,\n",
       " '47': 83,\n",
       " '48': 84,\n",
       " '49': 85,\n",
       " '50': 86,\n",
       " '51': 87,\n",
       " '52': 88,\n",
       " '53': 89,\n",
       " '54': 90,\n",
       " '55': 91,\n",
       " '56': 92,\n",
       " '57': 93,\n",
       " '58': 94,\n",
       " '59': 95,\n",
       " '60': 96,\n",
       " '61': 97,\n",
       " '62': 98,\n",
       " '63': 99,\n",
       " '64': 100,\n",
       " '65': 101,\n",
       " '66': 102,\n",
       " '67': 103,\n",
       " '68': 104,\n",
       " '69': 105,\n",
       " '70': 106,\n",
       " '71': 107,\n",
       " '72': 108,\n",
       " '73': 109,\n",
       " '74': 110,\n",
       " '75': 111,\n",
       " '76': 112,\n",
       " '77': 113,\n",
       " '78': 114,\n",
       " '79': 115,\n",
       " '80': 116,\n",
       " '81': 117,\n",
       " '82': 118,\n",
       " '83': 119,\n",
       " '84': 120,\n",
       " '85': 121,\n",
       " '86': 122,\n",
       " '87': 123}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = df_train + df_test\n",
    "word2idx, idx2word = get_mappings(all_data)\n",
    "\n",
    "max_input_len = max([len(story) for s, q, a in all_data for story in s])\n",
    "max_query_len = max([len(story) for s, q, a in all_data for story in s])\n",
    "max_no_of_sentences_in_story = max([len(s) for s, q, a in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mappings(data, max_input_len, max_query_len):\n",
    "    # Encode the mappings into the data\n",
    "    inputs, queries, outputs = [], [], []\n",
    "    for stories, question, answer in data:\n",
    "        inputs.append([[word2idx[word] for word in story] for story in stories])\n",
    "        queries.append([word2idx[word] for word in question])\n",
    "        outputs.append([word2idx[word] for word in answer])\n",
    "\n",
    "    # Pad sequences\n",
    "    inputs = [pad_sequences(x, maxlen=max_input_len) for x in inputs]\n",
    "    queries = pad_sequences(queries, maxlen=max_query_len)\n",
    "    \n",
    "    return inputs, queries, np.array(outputs)\n",
    "\n",
    "inputs_train, queries_train, outputs_train = encode_mappings(df_train, max_input_len, max_query_len)\n",
    "inputs_test, queries_test, outputs_test = encode_mappings(df_test, max_input_len, max_query_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_inputs(inputs, max_input_len, max_no_of_sentences_in_story):\n",
    "    \"\"\"\n",
    "    this is like 'pad_sequences' but for entire stories\n",
    "    we are padding each story with zeros so every story\n",
    "    has the same number of sentences\n",
    "    append an array of zeros of size:\n",
    "    (max_sentences - num sentences in story, max words in sentence)\n",
    "    \"\"\"\n",
    "    for i, story in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate(\n",
    "          [\n",
    "            story, \n",
    "            np.zeros((max_no_of_sentences_in_story - story.shape[0], max_input_len), 'int')\n",
    "          ]\n",
    "        )\n",
    "    return np.stack(inputs)\n",
    "\n",
    "inputs_train = stack_inputs(inputs_train, max_input_len, max_no_of_sentences_in_story)\n",
    "inputs_test = stack_inputs(inputs_test, max_input_len, max_no_of_sentences_in_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "EMBEDDING_DIM = 30\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes\n",
    "# embedded_story -> (vocab_size, max_no_of_sentences_in_story, EMBEDDING_DIM)\n",
    "# embedded_question -> (vocab_size, 1, EMBEDDING_DIM)\n",
    "\n",
    "# Model inputs\n",
    "input_story = Input((max_no_of_sentences_in_story, max_input_len))\n",
    "input_question = Input((max_query_len, ))\n",
    "\n",
    "# Model\n",
    "embedded_story = Embedding(vocab_size, EMBEDDING_DIM)(input_story)\n",
    "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
    "\n",
    "embedded_question = Embedding(vocab_size, EMBEDDING_DIM)(input_question)\n",
    "embedded_question = Lambda(lambda x: K.sum(x, axis=1))(embedded_question)\n",
    "\n",
    "# Hop 1\n",
    "embedded_question = Reshape((1, EMBEDDING_DIM))(embedded_question)\n",
    "x = dot([embedded_story, embedded_question], 2)\n",
    "x = Reshape((max_no_of_sentences_in_story, ))(x)  \n",
    "x = Activation(\"softmax\")(x)\n",
    "story_weights1 = Reshape((max_no_of_sentences_in_story, 1))(x)\n",
    "embedded_story = Embedding(vocab_size, EMBEDDING_DIM)(input_story)\n",
    "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
    "x = dot([story_weights1, embedded_story], 1)\n",
    "x = Reshape((EMBEDDING_DIM, ))(x)\n",
    "x = Dense(EMBEDDING_DIM, activation=\"elu\")(x)\n",
    "\n",
    "# Hop 2\n",
    "x = Reshape((1, EMBEDDING_DIM))(x)\n",
    "x = dot([embedded_story, x], 2)\n",
    "x = Reshape((max_no_of_sentences_in_story, ))(x)  \n",
    "x = Activation(\"softmax\")(x)\n",
    "story_weights2 = Reshape((max_no_of_sentences_in_story, 1))(x)\n",
    "embedded_story = Embedding(vocab_size, EMBEDDING_DIM)(input_story)\n",
    "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
    "x = dot([story_weights2, embedded_story], 1)\n",
    "x = Reshape((EMBEDDING_DIM, ))(x)\n",
    "x = Dense(EMBEDDING_DIM, activation=\"elu\")(x)\n",
    "\n",
    "output = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model([input_story, input_question], output)\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=5e-3), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 88, 8)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 8, 30)        3750        input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 88, 8, 30)    3750        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 30)           0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 88, 30)       0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_80 (Reshape)            (None, 1, 30)        0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 88, 1)        0           lambda_40[0][0]                  \n",
      "                                                                 reshape_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_81 (Reshape)            (None, 88)           0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 88, 8, 30)    3750        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 88)           0           reshape_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 88, 30)       0           embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_82 (Reshape)            (None, 88, 1)        0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 1, 30)        0           reshape_82[0][0]                 \n",
      "                                                                 lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_83 (Reshape)            (None, 30)           0           dot_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 30)           930         reshape_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_84 (Reshape)            (None, 1, 30)        0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 88, 1)        0           lambda_42[0][0]                  \n",
      "                                                                 reshape_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_85 (Reshape)            (None, 88)           0           dot_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 88)           0           reshape_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 88, 8, 30)    3750        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_86 (Reshape)            (None, 88, 1)        0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 88, 30)       0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 1, 30)        0           reshape_86[0][0]                 \n",
      "                                                                 lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_87 (Reshape)            (None, 30)           0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 30)           930         reshape_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 125)          3875        dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 20,735\n",
      "Trainable params: 20,735\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 10s 1ms/sample - loss: 1.7579 - accuracy: 0.2534 - val_loss: 1.5563 - val_accuracy: 0.3680\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 1.0187 - accuracy: 0.6049 - val_loss: 0.6944 - val_accuracy: 0.7340\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 8s 818us/sample - loss: 0.6249 - accuracy: 0.7639 - val_loss: 0.6219 - val_accuracy: 0.7720\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.5175 - accuracy: 0.8123 - val_loss: 0.5294 - val_accuracy: 0.8130\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.4341 - accuracy: 0.8436 - val_loss: 0.4731 - val_accuracy: 0.8360\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 9s 897us/sample - loss: 0.3721 - accuracy: 0.8677 - val_loss: 0.4685 - val_accuracy: 0.8260\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.3319 - accuracy: 0.8863 - val_loss: 0.3516 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 0.3103 - accuracy: 0.8985 - val_loss: 0.4944 - val_accuracy: 0.8440\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 9s 906us/sample - loss: 0.2844 - accuracy: 0.9060 - val_loss: 0.3875 - val_accuracy: 0.8740\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 8s 843us/sample - loss: 0.2697 - accuracy: 0.9133 - val_loss: 0.3790 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 9s 874us/sample - loss: 0.2435 - accuracy: 0.9253 - val_loss: 0.4153 - val_accuracy: 0.8820\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.2305 - accuracy: 0.9291 - val_loss: 0.4146 - val_accuracy: 0.8690\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 0.2260 - accuracy: 0.9332 - val_loss: 0.3839 - val_accuracy: 0.8900\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 10s 995us/sample - loss: 0.2111 - accuracy: 0.9348 - val_loss: 0.3819 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 15s 2ms/sample - loss: 0.2080 - accuracy: 0.9414 - val_loss: 0.3295 - val_accuracy: 0.8980\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.1984 - accuracy: 0.9420 - val_loss: 0.3147 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.1938 - accuracy: 0.9442 - val_loss: 0.3728 - val_accuracy: 0.9070\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 0.1717 - accuracy: 0.9515 - val_loss: 0.3678 - val_accuracy: 0.9070\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.1826 - accuracy: 0.9479 - val_loss: 0.3698 - val_accuracy: 0.8980\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.1753 - accuracy: 0.9519 - val_loss: 0.3883 - val_accuracy: 0.9020\n"
     ]
    }
   ],
   "source": [
    "result = model.fit([inputs_train, queries_train], outputs_train, epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
    "                   validation_data=([inputs_test, queries_test], outputs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "\n",
      "0.00000 \t 0.00000 \t 0 Mary picked up the apple there .\n",
      "0.00000 \t 0.00000 \t 1 John went back to the garden .\n",
      "0.00000 \t 0.00000 \t 2 Mary discarded the apple .\n",
      "0.00000 \t 0.36606 \t 3 Daniel travelled to the bathroom .\n",
      "0.00000 \t 0.00000 \t 4 Daniel grabbed the apple there .\n",
      "0.00000 \t 0.00002 \t 5 John went back to the bedroom .\n",
      "0.00000 \t 0.00002 \t 6 John travelled to the office .\n",
      "0.00000 \t 0.00000 \t 7 Sandra journeyed to the office .\n",
      "0.00000 \t 0.00000 \t 8 John went back to the bedroom .\n",
      "0.00000 \t 0.00000 \t 9 John journeyed to the bathroom .\n",
      "0.00000 \t 0.02029 \t 10 Daniel journeyed to the office .\n",
      "0.00000 \t 0.00000 \t 11 Mary journeyed to the bedroom .\n",
      "0.00000 \t 0.00000 \t 12 Sandra went to the hallway .\n",
      "0.00000 \t 0.06675 \t 13 Daniel moved to the garden .\n",
      "0.00000 \t 0.00000 \t 14 Sandra journeyed to the garden .\n",
      "0.00000 \t 0.00000 \t 15 Sandra went back to the kitchen .\n",
      "0.00000 \t 0.00001 \t 16 John moved to the garden .\n",
      "0.00000 \t 0.00009 \t 17 Mary travelled to the kitchen .\n",
      "0.00000 \t 0.00001 \t 18 Sandra went back to the bathroom .\n",
      "0.00000 \t 0.00000 \t 19 Mary moved to the garden .\n",
      "0.00000 \t 0.00000 \t 20 Mary journeyed to the kitchen .\n",
      "0.00000 \t 0.00000 \t 21 Sandra travelled to the office .\n",
      "0.00000 \t 0.06225 \t 22 Daniel journeyed to the bedroom .\n",
      "0.00000 \t 0.48449 \t 23 Daniel moved to the hallway .\n",
      "0.00000 \t 0.00002 \t 24 John travelled to the bedroom .\n",
      "0.00000 \t 0.00000 \t 25 Daniel took the milk there .\n",
      "1.00000 \t 0.00000 \t 26 Daniel put down the apple .\n",
      "0.00000 \t 0.00000 \t 27 Daniel grabbed the football there .\n",
      "Question: Where is the apple ?\n",
      "Answer: hallway\n",
      "Prediction:  hallway\n"
     ]
    }
   ],
   "source": [
    "# Check how we weight each input sentence given a story and question\n",
    "weights_model = Model([input_story, input_question], [story_weights1, story_weights2])\n",
    "\n",
    "# choose a random story\n",
    "story_idx = np.random.choice(len(inputs_train))\n",
    "\n",
    "# get weights from debug model\n",
    "i = inputs_train[story_idx:story_idx+1]\n",
    "q = queries_train[story_idx:story_idx+1]\n",
    "weights1, weights2 = weights_model.predict([i, q])\n",
    "weights1 = weights1.flatten()\n",
    "weights2 = weights2.flatten()\n",
    "idx = model.predict([i, q])\n",
    "\n",
    "story, question, ans = df_train[story_idx]\n",
    "\n",
    "print(\"Story:\\n\")\n",
    "for i, line in enumerate(story):\n",
    "    print(\"{:1.5f}\".format(weights1[i]), \"\\t\", \"{:1.5f}\".format(weights2[i]), \"\\t\", \" \".join(line))\n",
    "\n",
    "print(\"Question:\", \" \".join(question))\n",
    "print(\"Answer:\", ans[0])\n",
    "print(\"Prediction: \", idx2word[np.argmax(idx)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
